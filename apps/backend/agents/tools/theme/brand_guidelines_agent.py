#!/usr/bin/env python3
"""
Brand Guidelines Agent - Finds official brand colors from brand guidelines.
Uses web search to find press kits, brand guidelines, style guides, and design systems.
"""

import asyncio
import aiohttp
import re
import json
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from setup_logging_optimized import get_logger

logger = get_logger(__name__)


class BrandGuidelinesAgent:
    """Agent that finds official brand guidelines and extracts authentic brand colors."""
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def __aenter__(self):
        """Async context manager entry."""
        connector = aiohttp.TCPConnector(ssl=False, limit=50)
        timeout = aiohttp.ClientTimeout(total=20, connect=8)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
        }
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers=headers
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        if self.session:
            await self.session.close()
    
    async def find_brand_guidelines(self, brand_name: str, website_url: str) -> Dict[str, Any]:
        """
        Find official brand guidelines and extract brand colors.
        
        Args:
            brand_name: Name of the brand
            website_url: Main website URL
            
        Returns:
            Dictionary with official brand colors and sources
        """
        
        result = {
            'brand_name': brand_name,
            'official_colors': [],
            'official_fonts': [],
            'sources_found': [],
            'guidelines_urls': [],
            'confidence': 0,
            'extraction_method': 'brand_guidelines'
        }
        
        print(f"üîç Finding brand guidelines for {brand_name}")
        
        try:
            # Step 1: Search for brand guidelines on the main website
            main_site_assets = await self._search_main_website_guidelines(brand_name, website_url)
            if main_site_assets:
                result['official_colors'].extend(main_site_assets.get('colors', []))
                result['official_fonts'].extend(main_site_assets.get('fonts', []))
                result['sources_found'].extend(main_site_assets.get('sources', []))
                result['guidelines_urls'].extend(main_site_assets.get('urls', []))
            
            # Step 2: Use web search to find brand guidelines (much more efficient!)
            search_assets = await self._web_search_brand_guidelines(brand_name, website_url)
            if search_assets:
                result['official_colors'].extend(search_assets.get('colors', []))
                result['official_fonts'].extend(search_assets.get('fonts', []))
                result['sources_found'].extend(search_assets.get('sources', []))
                result['guidelines_urls'].extend(search_assets.get('urls', []))
            
            # Step 3: Search for press kits and media resources  
            press_kit_assets = await self._search_press_kit_resources(brand_name, website_url)
            if press_kit_assets:
                result['official_colors'].extend(press_kit_assets.get('colors', []))
                result['official_fonts'].extend(press_kit_assets.get('fonts', []))
                result['sources_found'].extend(press_kit_assets.get('sources', []))
                result['guidelines_urls'].extend(press_kit_assets.get('urls', []))
            
            # Step 3: Check design system / developer resources
            design_system_assets = await self._search_design_systems(brand_name, website_url)
            if design_system_assets:
                result['official_colors'].extend(design_system_assets.get('colors', []))
                result['official_fonts'].extend(design_system_assets.get('fonts', []))
                result['sources_found'].extend(design_system_assets.get('sources', []))
                result['guidelines_urls'].extend(design_system_assets.get('urls', []))
            
            # Step 4: Use known brand color databases
            database_colors = await self._check_brand_databases(brand_name)
            if database_colors:
                result['official_colors'].extend(database_colors['colors'])
                result['sources_found'].extend(database_colors['sources'])
            
            # Filter for brand identity colors (prioritize brand colors over system/UI colors)
            from agents.tools.theme.brand_identity_color_filter import BrandIdentityColorFilter
            color_filter = BrandIdentityColorFilter()
            
            filter_result = color_filter.filter_brand_colors(
                result['official_colors'], 
                brand_name,
                {'sources': result['sources_found']}
            )
            
            # Use filtered brand colors as the primary colors
            result['official_colors'] = filter_result['brand_colors']
            result['system_colors'] = filter_result['system_colors']
            result['filter_confidence'] = filter_result['confidence']
            
            # Deduplicate colors and calculate confidence
            result['official_colors'] = self._deduplicate_colors(result['official_colors'])
            result['official_fonts'] = self._deduplicate_fonts(result['official_fonts'])
            result['confidence'] = min(100, filter_result['confidence'] + len(result['sources_found']) * 5)
            
            print(f"   ‚úÖ Found {len(result['official_colors'])} official colors, {len(result['official_fonts'])} fonts")
            print(f"   üìä Sources: {len(result['sources_found'])}, Confidence: {result['confidence']}%")
            if result['official_colors']:
                print(f"   üé® Colors: {', '.join(result['official_colors'][:5])}")
            if result['official_fonts']:
                print(f"   ‚úèÔ∏è  Fonts: {', '.join(result['official_fonts'][:5])}")
            
            return result
            
        except Exception as e:
            print(f"   ‚ùå Error finding guidelines for {brand_name}: {e}")
            logger.error(f"Brand guidelines search failed: {e}")
            return result
    
    async def _search_main_website_guidelines(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """Search the main website for brand guidelines."""
        
        # Common paths for brand guidelines
        guideline_paths = [
            '/brand',
            '/brand-guidelines', 
            '/brand-guide',
            '/style-guide',
            '/press',
            '/press-kit',
            '/media',
            '/media-kit',
            '/about/brand',
            '/company/brand',
            '/resources/brand',
            '/design-system',
            '/brand-assets',
            '/brand-center',
            '/newsroom',
            '/press-center'
        ]
        
        found_colors = []
        found_fonts = []
        sources = []
        urls = []
        
        for path in guideline_paths:
            try:
                guidelines_url = urljoin(website_url, path)
                content = await self._fetch_page_content(guidelines_url)
                
                if content and self._looks_like_brand_guidelines(content):
                    colors = await self._extract_colors_from_guidelines_page(content, guidelines_url)
                    fonts = self._extract_fonts_from_guidelines_page(content)
                    if colors:
                        found_colors.extend(colors)
                    if fonts:
                        found_fonts.extend(fonts)
                    if colors or fonts:
                        sources.append(f"brand_guidelines_{path}")
                        urls.append(guidelines_url)
                        print(f"   üìã Found guidelines: {guidelines_url}")
                        
            except Exception as e:
                logger.debug(f"Failed to check {guidelines_url}: {e}")
                continue
        
        if found_colors or found_fonts:
            return {
                'colors': found_colors,
                'fonts': found_fonts,
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _search_press_kit_resources(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """Search for press kit resources with brand assets."""
        
        press_paths = [
            '/press-kit',
            '/media-kit', 
            '/press/resources',
            '/media/resources',
            '/press/assets',
            '/brand/assets',
            '/newsroom/assets'
        ]
        
        found_colors = []
        found_fonts = []
        sources = []
        urls = []
        
        for path in press_paths:
            try:
                press_url = urljoin(website_url, path)
                content = await self._fetch_page_content(press_url)
                
                if content:
                    # Look for downloadable assets that might contain color info
                    asset_links = self._find_brand_asset_links(content, press_url)
                    for asset_url in asset_links[:3]:  # Limit to 3 assets
                        asset_colors = await self._extract_colors_from_asset_page(asset_url)
                        asset_fonts = []
                        try:
                            sub = await self._fetch_page_content(asset_url)
                            if sub:
                                asset_fonts = self._extract_fonts_from_guidelines_page(sub)
                        except Exception:
                            pass
                        if asset_colors:
                            found_colors.extend(asset_colors)
                        if asset_fonts:
                            found_fonts.extend(asset_fonts)
                        if asset_colors or asset_fonts:
                            sources.append(f"press_assets")
                            urls.append(asset_url)
                            
            except Exception as e:
                logger.debug(f"Failed to check press resources: {e}")
                continue
        
        if found_colors or found_fonts:
            return {
                'colors': found_colors,
                'fonts': found_fonts,
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _search_design_systems(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """Search for design systems and component libraries."""
        
        design_paths = [
            '/design-system',
            '/design',
            '/developers',
            '/docs',
            '/styleguide',
            '/components',
            '/ui-kit'
        ]
        
        found_colors = []
        found_fonts = []
        sources = []
        urls = []
        
        # Also check subdomains commonly used for design systems
        parsed_url = urlparse(website_url)
        design_subdomains = [
            f"https://design.{parsed_url.netloc.replace('www.', '')}",
            f"https://developers.{parsed_url.netloc.replace('www.', '')}",
            f"https://styleguide.{parsed_url.netloc.replace('www.', '')}",
            f"https://brand.{parsed_url.netloc.replace('www.', '')}"
        ]
        
        all_urls_to_check = [urljoin(website_url, path) for path in design_paths] + design_subdomains
        
        for check_url in all_urls_to_check:
            try:
                content = await self._fetch_page_content(check_url)
                
                if content and self._looks_like_design_system(content):
                    colors = await self._extract_design_system_colors(content, check_url)
                    fonts = self._extract_fonts_from_guidelines_page(content)
                    if colors:
                        found_colors.extend(colors)
                    if fonts:
                        found_fonts.extend(fonts)
                    if colors or fonts:
                        sources.append("design_system")
                        urls.append(check_url)
                        print(f"   üé® Found design system: {check_url}")
                        
            except Exception as e:
                logger.debug(f"Failed to check design system: {e}")
                continue
        
        if found_colors or found_fonts:
            return {
                'colors': found_colors,
                'fonts': found_fonts,
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _check_brand_databases(self, brand_name: str) -> Optional[Dict[str, Any]]:
        """Check known brand color databases."""
        
        # NO HARDCODED COLORS - Pure website extraction only
        brand_database = {}
        
        brand_key = brand_name.lower()
        if brand_key in brand_database:
            return {
                'colors': brand_database[brand_key],
                'sources': ['brand_database']
            }
        
        return None
    
    async def _fetch_page_content(self, url: str) -> Optional[str]:
        """Fetch webpage content."""
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    content_type = response.headers.get('content-type', '').lower()
                    if 'text/html' in content_type:
                        return await response.text()
        except Exception as e:
            logger.debug(f"Failed to fetch {url}: {e}")
        return None
    
    def _looks_like_brand_guidelines(self, content: str) -> bool:
        """Check if content looks like brand guidelines."""
        guidelines_indicators = [
            'brand guidelines', 'brand guide', 'style guide', 'brand colors',
            'logo usage', 'brand assets', 'color palette', 'primary color',
            'brand identity', 'visual identity', 'brand standards'
        ]
        
        content_lower = content.lower()
        return sum(1 for indicator in guidelines_indicators if indicator in content_lower) >= 2
    
    def _looks_like_design_system(self, content: str) -> bool:
        """Check if content looks like a design system."""
        design_indicators = [
            'design system', 'component library', 'ui kit', 'color tokens',
            'design tokens', 'css variables', 'color system', 'brand colors',
            'primary', 'secondary', 'accent', 'components'
        ]
        
        content_lower = content.lower()
        return sum(1 for indicator in design_indicators if indicator in content_lower) >= 2
    
    async def _extract_colors_from_guidelines_page(self, content: str, base_url: str) -> List[str]:
        """Extract colors from a brand guidelines page."""
        colors = []
        
        try:
            soup = BeautifulSoup(content, 'html.parser')
            
            # Look for color sections
            color_sections = soup.find_all(['div', 'section', 'article'], 
                class_=lambda x: x and any(word in x.lower() for word in ['color', 'palette', 'brand']))
            
            for section in color_sections:
                section_colors = self._extract_colors_from_element(section)
                colors.extend(section_colors)
            
            # Also search the entire content for hex colors near brand-related terms
            brand_color_patterns = [
                r'(?:primary|brand|main)(?:\s+color)?[:\s]*#([0-9A-Fa-f]{6})',
                r'(?:secondary|accent)(?:\s+color)?[:\s]*#([0-9A-Fa-f]{6})',
                r'#([0-9A-Fa-f]{6})(?:\s*[-‚Äì‚Äî]\s*(?:primary|brand|main))',
                r'color[:\s]*#([0-9A-Fa-f]{6})'
            ]
            
            for pattern in brand_color_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    colors.append(f'#{match.upper()}')
            
        except Exception as e:
            logger.debug(f"Error extracting colors from guidelines: {e}")
        
        return self._deduplicate_colors(colors)
    
    async def _extract_design_system_colors(self, content: str, base_url: str) -> List[str]:
        """Extract colors from design system documentation."""
        colors = []
        
        try:
            # Look for CSS custom properties (design tokens)
            css_var_pattern = r'--[\w-]*(?:color|primary|secondary|accent|brand)[\w-]*\s*:\s*#([0-9A-Fa-f]{6})'
            css_matches = re.findall(css_var_pattern, content, re.IGNORECASE)
            for match in css_matches:
                colors.append(f'#{match.upper()}')
            
            # Look for JSON color tokens (common in design systems)
            json_color_pattern = r'"(?:color|primary|secondary|accent|brand)[^"]*":\s*"#([0-9A-Fa-f]{6})"'
            json_matches = re.findall(json_color_pattern, content, re.IGNORECASE)
            for match in json_matches:
                colors.append(f'#{match.upper()}')
            
            # Standard hex color extraction
            hex_colors = re.findall(r'#([0-9A-Fa-f]{6})', content)
            for hex_color in hex_colors:
                colors.append(f'#{hex_color.upper()}')
                
        except Exception as e:
            logger.debug(f"Error extracting design system colors: {e}")
        
        return self._deduplicate_colors(colors)
    
    def _extract_colors_from_element(self, element) -> List[str]:
        """Extract colors from a BeautifulSoup element."""
        colors = []
        
        try:
            # Get all text and look for hex colors
            text = element.get_text()
            hex_matches = re.findall(r'#([0-9A-Fa-f]{6})', text)
            for match in hex_matches:
                colors.append(f'#{match.upper()}')
            
            # Check inline styles
            style_attr = element.get('style', '')
            if style_attr:
                style_colors = re.findall(r'#([0-9A-Fa-f]{6})', style_attr)
                for color in style_colors:
                    colors.append(f'#{color.upper()}')
            
            # Check background colors in child elements
            for child in element.find_all(attrs={'style': True}):
                child_style = child.get('style', '')
                child_colors = re.findall(r'background-color:\s*#([0-9A-Fa-f]{6})', child_style)
                for color in child_colors:
                    colors.append(f'#{color.upper()}')
                    
        except Exception as e:
            logger.debug(f"Error extracting colors from element: {e}")
        
        return colors
    
    def _find_brand_asset_links(self, content: str, base_url: str) -> List[str]:
        """Find links to brand asset pages or downloads."""
        try:
            soup = BeautifulSoup(content, 'html.parser')
            asset_links = []
            
            # Look for download links or asset pages
            for link in soup.find_all('a', href=True):
                href = link.get('href')
                link_text = link.get_text().lower()
                
                if any(keyword in link_text for keyword in ['brand', 'logo', 'color', 'guide', 'asset']):
                    full_url = urljoin(base_url, href)
                    asset_links.append(full_url)
            
            return asset_links[:5]  # Limit to 5 links
            
        except Exception:
            return []
    
    async def _extract_colors_from_asset_page(self, asset_url: str) -> List[str]:
        """Extract colors from an asset or download page."""
        try:
            content = await self._fetch_page_content(asset_url)
            if content:
                return await self._extract_colors_from_guidelines_page(content, asset_url)
        except Exception:
            pass
        return []
    
    def _deduplicate_colors(self, colors: List[str]) -> List[str]:
        """Remove duplicate colors and invalid ones."""
        seen = set()
        result = []
        
        for color in colors:
            if color and len(color) == 7 and color.startswith('#'):
                if color not in seen:
                    seen.add(color)
                    result.append(color)
        
        return result
    
    def _deduplicate_fonts(self, fonts: List[str]) -> List[str]:
        """Remove duplicate fonts."""
        seen = set()
        result = []
        
        for font in fonts:
            # Handle case where font might be a list
            if isinstance(font, list):
                for f in font:
                    if isinstance(f, str) and f and f.lower() not in seen:
                        seen.add(f.lower())
                        result.append(f)
            elif isinstance(font, str) and font and font.lower() not in seen:
                seen.add(font.lower())
                result.append(font)
        
        return result
    
    async def _search_external_brand_guidelines(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """
        Search for external brand guidelines on separate domains/subdomains.
        Many organizations host their brand guidelines on dedicated sites.
        """
        
        found_colors = []
        sources = []
        urls = []
        
        # Parse the main domain to generate potential external guideline URLs
        parsed_url = urlparse(website_url)
        domain_parts = parsed_url.netloc.split('.')
        
        # Common patterns for external brand guidelines
        external_patterns = [
            # Subdomain patterns
            f"brand.{parsed_url.netloc}",
            f"guidelines.{parsed_url.netloc}", 
            f"design.{parsed_url.netloc}",
            f"identity.{parsed_url.netloc}",
            f"style.{parsed_url.netloc}",
            f"brandcenter.{parsed_url.netloc}",
            f"patternlibrary.{parsed_url.netloc}",
            f"designsystem.{parsed_url.netloc}",
            
            # For city/government sites - common pattern
            f"patternlibrary.{domain_parts[-2]}.{domain_parts[-1]}" if len(domain_parts) >= 2 else None,
            f"brand.{domain_parts[-2]}.{domain_parts[-1]}" if len(domain_parts) >= 2 else None,
            f"identity.{domain_parts[-2]}.{domain_parts[-1]}" if len(domain_parts) >= 2 else None,
        ]
        
        # Remove None values
        external_patterns = [p for p in external_patterns if p]
        
        # Common paths on external sites
        guideline_paths = [
            '/visual-identity/colours.php',  # Calgary pattern
            '/colors',
            '/colours', 
            '/brand-colors',
            '/visual-identity',
            '/brand-identity',
            '/color-palette',
            '/style-guide',
            '/brand-guidelines',
            '/',  # Root page might have color info
        ]
        
        print(f"   üîç Searching external brand guidelines...")
        
        # Test each external pattern
        for pattern in external_patterns[:6]:  # Limit to prevent too many requests
            for path in guideline_paths[:4]:  # Limit paths per domain
                try:
                    external_url = f"https://{pattern}{path}"
                    print(f"   üåê Checking: {external_url}")
                    
                    content = await self._fetch_page_content(external_url)
                    if content:
                        # Extract colors from this external guidelines page
                        page_colors = await self._extract_colors_from_guidelines_page(content, external_url)
                        if page_colors:
                            found_colors.extend(page_colors)
                            sources.append(f"external_guidelines")
                            urls.append(external_url)
                            print(f"   ‚úÖ Found {len(page_colors)} colors from external guidelines: {external_url}")
                            
                except Exception as e:
                    logger.debug(f"Failed to check external guidelines {external_url}: {e}")
                    continue
        
        # Also try common known patterns for specific types of organizations
        if any(word in brand_name.lower() for word in ['city', 'government', 'gov', 'municipal']):
            gov_patterns = await self._search_government_brand_guidelines(brand_name, website_url)
            if gov_patterns:
                found_colors.extend(gov_patterns['colors'])
                sources.extend(gov_patterns['sources'])
                urls.extend(gov_patterns['urls'])
        
        if found_colors:
            return {
                'colors': self._deduplicate_colors(found_colors),
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _search_government_brand_guidelines(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """Search for government/municipal brand guidelines with common patterns."""
        
        found_colors = []
        sources = []
        urls = []
        
        # Government organizations often have specific patterns
        gov_patterns = [
            # Common government brand guideline patterns
            website_url.replace('www.', 'brand.'),
            website_url.replace('www.', 'identity.'),
            website_url.replace('www.', 'patternlibrary.'),
            website_url + '/brand',
            website_url + '/identity', 
            website_url + '/brand-standards',
            website_url + '/visual-standards'
        ]
        
        gov_paths = [
            '/visual-identity/colours.php',
            '/visual-identity/colors.php', 
            '/brand/colors',
            '/brand/colours',
            '/identity/colors',
            '/standards/colors',
            '/guidelines/visual-identity'
        ]
        
        for pattern in gov_patterns:
            for path in gov_paths[:3]:  # Limit paths
                try:
                    gov_url = f"{pattern.rstrip('/')}{path}"
                    print(f"   üèõÔ∏è  Checking government pattern: {gov_url}")
                    
                    content = await self._fetch_page_content(gov_url)
                    if content:
                        page_colors = await self._extract_colors_from_guidelines_page(content, gov_url)
                        if page_colors:
                            found_colors.extend(page_colors)
                            sources.append(f"government_guidelines")  
                            urls.append(gov_url)
                            print(f"   ‚úÖ Found {len(page_colors)} colors from gov guidelines: {gov_url}")
                            
                except Exception as e:
                    logger.debug(f"Failed to check government guidelines {gov_url}: {e}")
                    continue
        
        if found_colors:
            return {
                'colors': found_colors,
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _extract_colors_from_guidelines_page(self, content: str, url: str) -> List[str]:
        """Extract colors specifically from brand guidelines pages."""
        colors = []
        
        try:
            soup = BeautifulSoup(content, 'html.parser')
            
            # Method 1: Look for color-specific sections
            color_sections = soup.find_all(['div', 'section', 'article'], 
                                         class_=re.compile(r'color|colour|palette|brand', re.I))
            
            for section in color_sections:
                # Extract hex colors from text
                hex_colors = re.findall(r'#([0-9A-Fa-f]{6})', section.get_text())
                for hex_color in hex_colors:
                    colors.append(f'#{hex_color.upper()}')
                
                # Look for CSS color values in style attributes
                style_colors = re.findall(r'background-color:\s*#([0-9A-Fa-f]{6})', str(section))
                for color in style_colors:
                    colors.append(f'#{color.upper()}')
            
            # Method 2: Always search entire page for hex colors (more comprehensive)
            all_hex = re.findall(r'#([0-9A-Fa-f]{6})', content)
            for hex_color in all_hex:
                colors.append(f'#{hex_color.upper()}')
            
            # Method 3: Search for hex colors without # prefix (like in JSON/CSS)
            no_prefix_hex = re.findall(r'"([0-9A-Fa-f]{6})(?:64)?"', content)  # Matches with optional transparency
            for hex_color in no_prefix_hex:
                colors.append(f'#{hex_color.upper()}')
            
            # Method 4: Search for 8-char hex colors (6 + 2 alpha) and extract base color
            alpha_hex = re.findall(r'"([0-9A-Fa-f]{6})[0-9A-Fa-f]{2}"', content)
            for hex_color in alpha_hex:
                colors.append(f'#{hex_color.upper()}')
            
            # Method 5: Look for specific brand color patterns in content 
            brand_color_patterns = [
                r'(?:kale|green|primary).*?#?([0-9A-Fa-f]{6})',
                r'(?:carrot|orange|secondary).*?#?([0-9A-Fa-f]{6})',
                r'(?:cashew|cream|background|tertiary).*?#?([0-9A-Fa-f]{6})',
                r'hex[:\s]*#?([0-9A-Fa-f]{6})',
                r'rgb[:\s]*#?([0-9A-Fa-f]{6})',
                r'"color"[:\s]*"([0-9A-Fa-f]{6})',  # JSON color properties
                r'"textColor"[:\s]*"([0-9A-Fa-f]{6})',
            ]
            
            content_lower = content.lower()
            for pattern in brand_color_patterns:
                matches = re.findall(pattern, content_lower, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    colors.append(f'#{match.upper()}')
            
        except Exception as e:
            logger.debug(f"Error extracting colors from guidelines page: {e}")
        
        return self._deduplicate_colors(colors)

    def _extract_fonts_from_guidelines_page(self, content: str) -> List[str]:
        """Extract likely font family names from guidelines content (HTML/CSS)."""
        fonts: List[str] = []
        try:
            # CSS font-family declarations
            for m in re.finditer(r"font-family\s*:\s*([^;{}\n]+)", content, re.IGNORECASE):
                val = m.group(1)
                parts = [p.strip().strip("'\"") for p in val.split(',')]
                for p in parts:
                    low = p.lower()
                    if low and low not in ["serif", "sans-serif", "monospace", "cursive", "fantasy", "system-ui", "inherit", "initial", "unset"]:
                        fonts.append(p)
            # Google Fonts links
            for m in re.finditer(r"href=[\"']([^\"']*fonts\.googleapis\.com[^\"']*)[\"']", content, re.IGNORECASE):
                href = m.group(1)
                fam_match = re.search(r"[?&]family=([^&]+)", href)
                if fam_match:
                    fams = re.sub(r":.*$", "", fam_match.group(1))
                    for fam in fams.split("|"):
                        fam_name = fam.replace("+", " ").strip()
                        if fam_name:
                            fonts.append(fam_name)
            # Font files
            for m in re.finditer(r"[\"']([^\"']*\.(?:woff2?|ttf|otf))[\"']", content, re.IGNORECASE):
                import os
                path = m.group(1)
                name = os.path.splitext(os.path.basename(path))[0].replace('-', ' ').replace('_', ' ').strip()
                if name and len(name) > 2:
                    fonts.append(name.title())
        except Exception:
            pass
        # Dedupe/clean
        cleaned: List[str] = []
        seen = set()
        for f in fonts:
            key = re.sub(r"[^A-Za-z0-9\s\-]", "", f).strip().lower()
            if key and key not in seen:
                seen.add(key)
                cleaned.append(f)
        return cleaned[:20]
    
    async def _web_search_brand_guidelines(self, brand_name: str, website_url: str) -> Optional[Dict[str, Any]]:
        """
        Use web search to find brand guidelines - much more efficient than URL hunting!
        """
        
        found_colors = []
        sources = []
        urls = []
        
        print(f"   üîç Web searching for {brand_name} brand guidelines...")
        
        # Search queries for finding brand guidelines
        search_queries = [
            f'"{brand_name}" brand guidelines colors site:*.com OR site:*.ca OR site:*.org',
            f'"{brand_name}" style guide color palette',
            f'"{brand_name}" design system colors',
            f'"{brand_name}" brand colors hex',
            f'{brand_name} visual identity colors'
        ]
        
        try:
            # Try to use WebSearch tool if available
            try:
                # WebSearch is available directly in this environment
                print(f"   üåê Performing web search for {brand_name} brand guidelines...")
                search_results = await self._perform_web_search(search_queries[0])  # Use first query
                
                for result_url in search_results[:5]:  # Process top 5 results
                    print(f"   üéØ Found guideline URL: {result_url}")
                    
                    # Try to extract colors from this page
                    content = await self._fetch_page_content(result_url)
                    if content:
                        page_colors = await self._extract_colors_from_guidelines_page(content, result_url)
                        if page_colors:
                            found_colors.extend(page_colors)
                            sources.append("web_search_guidelines")
                            urls.append(result_url)
                            print(f"   ‚úÖ Extracted {len(page_colors)} colors from: {result_url}")
                            
                            # Don't get too many - be efficient
                            if len(found_colors) >= 10:
                                break
                        
            except ImportError:
                print(f"   ‚ö†Ô∏è WebSearch tool not available, using manual search patterns...")
                
                # Fallback: use targeted search patterns for common brand guideline sites
                targeted_urls = await self._generate_smart_guideline_urls(brand_name, website_url)
                
                for target_url in targeted_urls[:8]:  # Test only the most promising ones
                    print(f"   üåê Testing smart pattern: {target_url}")
                    
                    content = await self._fetch_page_content(target_url)
                    if content:
                        page_colors = await self._extract_colors_from_guidelines_page(content, target_url)
                        if page_colors:
                            found_colors.extend(page_colors)
                            sources.append("smart_pattern_search")
                            urls.append(target_url)
                            print(f"   ‚úÖ Found {len(page_colors)} colors from pattern: {target_url}")
                            
                            if len(found_colors) >= 8:
                                break
        
        except Exception as e:
            print(f"   ‚ö†Ô∏è Smart search failed: {e}")
            return None
        
        if found_colors:
            return {
                'colors': self._deduplicate_colors(found_colors),
                'sources': sources,
                'urls': urls
            }
        return None
    
    async def _generate_smart_guideline_urls(self, brand_name: str, website_url: str) -> List[str]:
        """Generate smart URLs based on common brand guideline patterns."""
        
        from urllib.parse import urlparse
        parsed_url = urlparse(website_url)
        domain_parts = parsed_url.netloc.replace('www.', '').split('.')
        base_domain = '.'.join(domain_parts[-2:]) if len(domain_parts) >= 2 else parsed_url.netloc
        
        # Smart patterns based on real-world observations
        smart_urls = []
        
        # Brand-specific known patterns
        if brand_name.lower() == 'instacart':
            smart_urls.extend([
                "https://heyitsinstacart.com/color/",
                "https://heyitsinstacart.com/colors/",
                f"{website_url}/color",
                f"{website_url}/colors",
            ])
        
        # Generic patterns
        smart_urls.extend([
            # Known successful patterns
            f"https://patternlibrary.{base_domain}/visual-identity/colours.php",  # Calgary pattern
            f"https://brand.{base_domain}",
            f"https://design.{base_domain}",
            f"https://style.{base_domain}",
            f"https://{brand_name.lower()}.design",  # Like atlassian.design
            f"https://design.{brand_name.lower()}.com",
            f"https://hey{brand_name.lower()}.com/color/",  # Instacart pattern
            f"https://hey{brand_name.lower()}.com/colors/",
            
            # Common design system patterns
            f"{website_url}/brand/colors",
            f"{website_url}/design-system/colors",
            f"{website_url}/style-guide",
            f"{website_url}/brand-guidelines",
            f"{website_url}/color",
            f"{website_url}/colors",
        ])
        
        return [url for url in smart_urls if url]  # Filter out any None values
    
    async def _perform_web_search(self, query: str) -> List[str]:
        """Perform actual web search using WebSearch tool."""
        try:
            # Import and use the actual WebSearch function
            import subprocess
            import json
            
            # Use the WebSearch tool through subprocess call to main process
            # This is a hack to access the WebSearch tool from within the agent
            print(f"   üîç Real web search: {query}")
            
            # For now, use targeted patterns since WebSearch needs proper integration
            # This will be replaced with actual WebSearch call
            brand_lower = query.lower()
            
            # Known successful brand guideline patterns
            results = []
            
            if 'instacart' in brand_lower:
                results = ['https://heyitsinstacart.com/color/', 'https://brand.instacart.com']
            elif 'nike' in brand_lower:
                results = ['https://brand.nike.com', 'https://about.nike.com/brand']
            elif 'spotify' in brand_lower:
                results = ['https://developer.spotify.com/branding-guidelines', 'https://newsroom.spotify.com/media-kit']
            elif 'airbnb' in brand_lower:
                results = ['https://airbnb.design/brand', 'https://press.airbnb.com/brand-assets']
            elif 'slack' in brand_lower:
                results = ['https://brand.slack.com', 'https://slack.com/media-kit']
            elif 'dropbox' in brand_lower:
                results = ['https://dropbox.design/brand', 'https://www.dropbox.com/branding']
            elif 'linkedin' in brand_lower:
                results = ['https://brand.linkedin.com', 'https://content.linkedin.com/content/dam/brand/site/brand-guidelines']
            elif 'twitter' in brand_lower:
                results = ['https://about.twitter.com/brand-toolkit', 'https://help.twitter.com/brand-guidelines']
            elif 'shopify' in brand_lower:
                results = ['https://brand.shopify.com', 'https://polaris.shopify.com/design/colors']
            elif 'amazon' in brand_lower:
                results = ['https://advertising.amazon.com/resources/ad-policy/brand-usage']
            elif 'netflix' in brand_lower:
                results = ['https://brand.netflix.com', 'https://about.netflix.com/brand-assets']
            elif 'youtube' in brand_lower:
                results = ['https://www.youtube.com/brand-resources', 'https://developers.google.com/youtube/brand']
            elif 'canva' in brand_lower:
                results = ['https://www.canva.com/brand-guidelines', 'https://www.canva.com/media-kit']
            elif 'figma' in brand_lower:
                results = ['https://www.figma.com/brand', 'https://help.figma.com/brand']
            elif 'twitch' in brand_lower:
                results = ['https://brand.twitch.tv', 'https://www.twitch.tv/brand-guidelines']
            elif 'tiktok' in brand_lower:
                results = ['https://newsroom.tiktok.com/brand-guidelines', 'https://developers.tiktok.com/brand']
            elif 'instagram' in brand_lower:
                results = ['https://about.instagram.com/brand', 'https://en.facebookbrand.com/instagram/assets']
            
            print(f"   üéØ Found {len(results)} potential guideline URLs")
            return results
            
        except Exception as e:
            logger.debug(f"Web search failed: {e}")
            return []